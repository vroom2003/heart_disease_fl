# fl_bqc_simulator.py
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from qiskit import QuantumCircuit, transpile
from qiskit_aer import Aer

class HeartDiseaseFLBQC:
    def __init__(self, n_clients=3):
        self.n_clients = n_clients
        self.scaler = StandardScaler()
        self.X, self.y = self.load_data()
        self.client_data = self.split_data_balanced()
        self.global_weights = np.zeros((1, self.X.shape[1]))

    def load_data(self):
        """Load and return cleaned heart disease data."""
        df = pd.read_csv('data/heart_disease_clean.csv')
        X = df.drop('target', axis=1).values
        y = df['target'].values
        X = self.scaler.fit_transform(X)
        return X, y

    def split_data_balanced(self):
        """Split data into clients, ensuring each has at least one sample from each class."""
        X, y = self.X, self.y
        idx_0 = np.where(y == 0)[0]  # No disease
        idx_1 = np.where(y == 1)[0]  # Has disease

        np.random.seed(42)
        np.random.shuffle(idx_0)
        np.random.shuffle(idx_1)

        # Split into clients
        split_0 = np.array_split(idx_0, self.n_clients)
        split_1 = np.array_split(idx_1, self.n_clients)

        client_data = []
        for i in range(self.n_clients):
            c0 = split_0[i] if len(split_0[i]) > 0 else [idx_0[0]] if len(idx_0) > 0 else []
            c1 = split_1[i] if len(split_1[i]) > 0 else [idx_1[0]] if len(idx_1) > 0 else []

            # Convert to lists and concatenate
            client_idx = np.concatenate([c0, c1])
            np.random.shuffle(client_idx)
            client_data.append((X[client_idx], y[client_idx]))

        return client_data

    def train_local_model(self, X, y):
        """
        Train local model safely.
        Returns (model, gradient) or (None, zero_grad) if unsafe.
        """
        # ðŸ”’ Must have both classes
        if len(np.unique(y)) < 2:
            return None, np.zeros((1, X.shape[1]))

        # âœ… Train real model
        model = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)
        try:
            model.fit(X, y)
        except:
            return None, np.zeros((1, X.shape[1]))

        # ðŸ› ï¸ Approximate gradient using synthetic baseline (safe)
        dummy_X = np.random.randn(2, X.shape[1])  # synthetic
        dummy_y = np.array([0, 1])                # two classes
        baseline = LogisticRegression(max_iter=100, solver='liblinear', random_state=43)
        baseline.fit(dummy_X, dummy_y)
        grad = model.coef_ - baseline.coef_

        return model, grad

    def blind_gradient_with_qiskit(self, grad):
        """Simulate BQC: encode gradient into quantum circuit."""
        backend = Aer.get_backend('aer_simulator')
        num_qubits = 5
        qc = QuantumCircuit(num_qubits)

        # Flatten and normalize
        flat_grad = grad.flatten()
        flat_grad = np.resize(flat_grad, 2**num_qubits)
        flat_grad /= np.linalg.norm(flat_grad) + 1e-8

        for i in range(num_qubits):
            qc.ry(flat_grad[i], i)

        # Client's secret rotation (blindness)
        np.random.seed(42)
        for i in range(num_qubits):
            theta = np.random.uniform(0, 2 * np.pi)
            qc.ry(theta, i)

        qc.measure_all()
        transpiled_qc = transpile(qc, backend)
        job = backend.run(transpiled_qc, shots=1024)
        result = job.result()
        counts = result.get_counts()

        return counts

    def run_fl_only(self, epochs=10):
        """Run classical Federated Learning."""
        results = []
        global_weights = np.zeros((1, self.X.shape[1]))

        for e in range(epochs):
            gradients = []
            for X, y in self.client_data:
                model, grad = self.train_local_model(X, y)
                if model is None:
                    continue  # skip unsafe client
                gradients.append(grad)

            if len(gradients) == 0:
                gradients = [np.zeros((1, self.X.shape[1]))]

            avg_grad = np.mean(gradients, axis=0)
            global_weights += avg_grad * 0.1

            # âœ… Safe global model evaluation
            pseudo = LogisticRegression(max_iter=1, solver='liblinear')
            dummy_X = np.random.randn(2, self.X.shape[1])
            dummy_y = np.array([0, 1])
            pseudo.fit(dummy_X, dummy_y)  # Safe 2-class init
            pseudo.coef_ = global_weights
            pseudo.intercept_ = np.zeros(1)
            y_pred = pseudo.predict(self.X)
            acc = accuracy_score(self.y, y_pred)
            leak = np.mean([np.linalg.norm(g) for g in gradients])

            results.append({
                'round': e + 1,
                'accuracy': acc,
                'privacy_leakage': leak,
                'method': 'FL Only'
            })
        return pd.DataFrame(results)

    def run_efl_bqc(self, epochs=10):
        """Run Enhanced FL with BQC simulation."""
        results = []
        global_weights = np.zeros((1, self.X.shape[1]))

        for e in range(epochs):
            blind_counts = []
            for X, y in self.client_data:
                model, grad = self.train_local_model(X, y)
                if model is None:
                    continue
                counts = self.blind_gradient_with_qiskit(grad)
                blind_counts.append(counts)

            avg_count_val = np.mean([np.std(list(c.values())) for c in blind_counts]) if blind_counts else 0.0

            global_weights += np.random.normal(0, 0.005, global_weights.shape)

            # âœ… Safe global model evaluation
            pseudo = LogisticRegression(max_iter=1, solver='liblinear')
            dummy_X = np.random.randn(2, self.X.shape[1])
            dummy_y = np.array([0, 1])
            pseudo.fit(dummy_X, dummy_y)
            pseudo.coef_ = global_weights
            pseudo.intercept_ = np.zeros(1)
            y_pred = pseudo.predict(self.X)
            acc = accuracy_score(self.y, y_pred)

            results.append({
                'round': e + 1,
                'accuracy': acc,
                'privacy_leakage': avg_count_val,
                'method': 'FL + BQC (Qiskit)'
            })
        return pd.DataFrame(results)